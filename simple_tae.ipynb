{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6825ca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94cded71",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST('~/Developer/datasets', transform=T.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b254dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shit_image(image):\n",
    "    dx = np.random.randint(-3, 4)\n",
    "    dy = np.random.randint(-3, 4)\n",
    "    image = torch.roll(image, dx, -1)\n",
    "    image = torch.roll(image, dy, -2)\n",
    "    return image, dx, dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84755f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "# Decoder\n",
    "# train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9fc77977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_conv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            # N, 1, 28, 28\n",
    "            nn.Conv2d(1, 32, 3, stride=2, padding=1), # N, 32, 14, 14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 16, 3, stride=2, padding=1), # N, 16, 7, 7\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 4, stride=2, padding=1), # N, 16, 3, 3\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 8, 3), # N, 8, 1, 1\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 4, 1), # N, 2, 1, 1\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            # N, 64, 1, 1\n",
    "            nn.ConvTranspose2d(4, 8, 1), # N, 2, 1, 1\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(8, 16, 3), # N, \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 16, 4, stride=2, padding=1, output_padding=1), # N, \n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 32, 3, stride=2, padding=1, output_padding=1), # N,\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 3, stride=2, padding=1, output_padding=1),  # N, \n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    \n",
    "    def decode(self, z):\n",
    "        return self.decoder(z)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         encoded = self.encoder(x)\n",
    "#         decoded = self.decoder(encoded)\n",
    "#         return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e001f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epochs, conv):\n",
    "    loss = 0\n",
    "\n",
    "    for batch_features, target in train_loader:\n",
    "        # reshape mini-batch data to [N, 784] matrix\n",
    "        # load it to the active device\n",
    "        \n",
    "#         if conv == False:\n",
    "#             batch_features = batch_features.view(-1, 784).to(device)\n",
    "        new_features, dx, dy = shit_image(batch_features)\n",
    "        # reset the gradients back to zero\n",
    "        # PyTorch accumulates gradients on subsequent backward passes\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # compute reconstructions\n",
    "        # phase 1\n",
    "        z = model.encode(batch_features)\n",
    "        # phase 2\n",
    "        z_shifted = z + torch.Tensor([dx, dy, 0, 0]).view(1, 2, 1, 1).to(device)\n",
    "        # phase 3\n",
    "        outputs = model.decode(z_shifted)\n",
    "#         outputs = model(batch_features)\n",
    "\n",
    "        # compute training reconstruction loss\n",
    "        train_loss = criterion(outputs, new_features)\n",
    "        \n",
    "        # compute accumulated gradients\n",
    "        train_loss.backward()\n",
    "        \n",
    "        # perform parameter update based on current gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        # add the mini-batch training loss to epoch loss\n",
    "        loss += train_loss.item()\n",
    "    \n",
    "    # compute the epoch training loss\n",
    "    loss = loss / len(train_loader)\n",
    "    \n",
    "    # display the epoch training loss\n",
    "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epochs + 1, epochs, loss))\n",
    "    return outputs,batch_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "018b7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 x 5\n",
    "# [-2, -2] [-2. -1]., [-2. 0]., [-2. +1], [-2, +2]\n",
    "# [-1, -2] [-2. -1]., [-2. 0]., [-2. +1], [-2, +2]\n",
    "# [0, -2] [-2. -1]., [-2. 0]., [-2. +1], [-2, +2]\n",
    "# [1, -2] [-2. -1]., [-2. 0]., [-2. +1], [-2, +2]\n",
    "# [2, -2] [-2. -1]., [-2. 0]., [-2. +1], [-2, +2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d43144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
